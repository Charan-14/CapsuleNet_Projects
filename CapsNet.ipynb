{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CapsNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5Zll_9s_oBz"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSTdjFHsAEqm",
        "outputId": "4d03fdf9-7cdf-4d31-fd2d-fca025c8db5d"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 1.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S05yfuswBJdS"
      },
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkZXvdUSeoFo"
      },
      "source": [
        "np.random.seed(40)\n",
        "tf.set_random_seed(40)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNuBIoSJfawy",
        "outputId": "bb019af5-e080-4e6f-abca-94595df129a2"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-c50d5bb4a85c>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "u1TPSuiYgCJ0",
        "outputId": "95422bab-3703-4e8e-80f6-ce5720905598"
      },
      "source": [
        "n_samples = 6\n",
        "\n",
        "plt.figure(figsize=(n_samples*2, 3))\n",
        "\n",
        "for index in range(n_samples):\n",
        "    plt.subplot(1, n_samples, index+1)\n",
        "    sample = mnist.train.images[index].reshape(28,28)\n",
        "    plt.imshow(sample, cmap='binary')\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x216 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ1_BLu7iLxZ",
        "outputId": "9150ef8f-eb67-4462-fa8b-be414e60e892"
      },
      "source": [
        "mnist.train.labels[:n_samples]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 3, 4, 6, 1, 8], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XMomAackYBY"
      },
      "source": [
        "X = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32, name='X')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7KaoUxdnDsP"
      },
      "source": [
        "caps1_map = 32\n",
        "caps1_amount = caps1_map * 6 * 6 #1152 Capsules\n",
        "caps1_dims = 8"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQR7TgjprCHR"
      },
      "source": [
        "conv1_params = {\n",
        "    \"filters\": 256,\n",
        "    \"kernel_size\": 9,\n",
        "    \"strides\": 1,\n",
        "    \"padding\": \"valid\",\n",
        "    \"activation\": tf.nn.relu,\n",
        "}\n",
        "\n",
        "conv2_params = {\n",
        "    \"filters\": caps1_amount * caps1_dims, # 256 convolutional filters\n",
        "    \"kernel_size\": 9,\n",
        "    \"strides\": 2,\n",
        "    \"padding\": \"valid\",\n",
        "    \"activation\": tf.nn.relu\n",
        "}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1Fohw3x3zba",
        "outputId": "1994a996-6b70-418a-e9f1-4c7fcf617b62"
      },
      "source": [
        "conv1 = tf.layers.conv2d(X, name=\"conv1\", **conv1_params)\n",
        "conv2 = tf.layers.conv2d(conv1, name=\"conv2\", **conv2_params)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-3a2df923b7cc>:1: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZGfTtWB4NBt"
      },
      "source": [
        "caps1_raw = tf.reshape(conv2, [-1, caps1_amount, caps1_dims],\n",
        "                       name=\"caps1_raw\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A7Gr_qj4ayd"
      },
      "source": [
        "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
        "    with tf.name_scope(name, default_name=\"squash\"):\n",
        "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
        "                                     keep_dims=True)\n",
        "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
        "        squash_factor = squared_norm / (1. + squared_norm)\n",
        "        unit_vector = s / safe_norm\n",
        "        return squash_factor * unit_vector"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMVl5DpF4lmb",
        "outputId": "50e7c54f-e19a-405d-a564-860c609416b0"
      },
      "source": [
        "caps1_output = squash(caps1_raw, name=\"caps1_output\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-8037c6cbfef1>:4: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UcyGXZl4oZE"
      },
      "source": [
        "caps2_amount = 10\n",
        "caps2_dims = 16"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCCxczfy4tTX"
      },
      "source": [
        "init_sigma = 0.1\n",
        "\n",
        "W_init = tf.random_normal(\n",
        "    shape=(1, caps1_amount, caps2_amount, caps2_dims, caps1_dims),\n",
        "    stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
        "W = tf.Variable(W_init, name=\"W\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K66LK65Y4yWL"
      },
      "source": [
        "batch_size = tf.shape(X)[0]\n",
        "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndh-heMC47pa"
      },
      "source": [
        "caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
        "                                       name=\"caps1_output_expanded\")\n",
        "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
        "                                   name=\"caps1_output_tile\")\n",
        "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_amount, 1, 1],\n",
        "                             name=\"caps1_output_tiled\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Amog2zeJC3A2",
        "outputId": "dcb966e4-efe1-4348-f274-69ab7fbd73f0"
      },
      "source": [
        "W_tiled"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'W_tiled:0' shape=(?, 1152, 10, 16, 8) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYwarN6h5rLs",
        "outputId": "33b0a871-5fe0-44b2-a2ca-5fbfd30880c3"
      },
      "source": [
        "caps1_output_tiled"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'caps1_output_tiled_1:0' shape=(?, 1152, 10, 8, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCFVFFR16FQQ",
        "outputId": "af4b624a-13b9-48e8-c678-00feb780a492"
      },
      "source": [
        "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
        "                            name=\"caps2_predicted\")\n",
        "caps2_predicted"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'caps2_predicted_1:0' shape=(?, 1152, 10, 16, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO53aGkY6xPE"
      },
      "source": [
        "raw_weights = tf.zeros([batch_size, caps1_amount, caps2_amount, 1, 1],\n",
        "                       dtype=np.float32, name=\"raw_weights\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZjRPeFh7Kqv",
        "outputId": "a56a6eaf-52ab-4cce-a5ed-c64dcdaf4277"
      },
      "source": [
        "routing_weights = tf.nn.softmax(raw_weights, dim=2, name=\"routing_weights\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-27-86a489ae595f>:1: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "dim is deprecated, use axis instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-Vk3aXU7Od9"
      },
      "source": [
        "weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n",
        "                                   name=\"weighted_predictions\")\n",
        "weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,\n",
        "                             name=\"weighted_sum\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3KZ_6TZ7yBk"
      },
      "source": [
        "caps2_output_round_1 = squash(weighted_sum, axis=-2,\n",
        "                              name=\"caps2_output_round_1\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Kzpn5TIDNo4",
        "outputId": "9a1b516a-d356-4f90-e8eb-c53c314d9797"
      },
      "source": [
        "caps2_predicted"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'caps2_predicted_1:0' shape=(?, 1152, 10, 16, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgvN8MXp70j-",
        "outputId": "47781940-1cfc-466a-d714-a4dd0c1bc5c5"
      },
      "source": [
        "caps2_output_round_1"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'caps2_output_round_1/mul:0' shape=(?, 1, 10, 16, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFhp2l1g-qe_"
      },
      "source": [
        "caps2_output_round_1_tiled = tf.tile(\n",
        "    caps2_output_round_1, [1, caps1_amount, 1, 1, 1],\n",
        "    name=\"caps2_output_round_1_tiled\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FadB36V--5z2"
      },
      "source": [
        "agreement = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,\n",
        "                      transpose_a=True, name=\"agreement\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxVUMoGJ_BPH"
      },
      "source": [
        "raw_weights_round_2 = tf.add(raw_weights, agreement,\n",
        "                             name=\"raw_weights_round_2\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89PiFeOw_F4q"
      },
      "source": [
        "routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,\n",
        "                                        dim=2,\n",
        "                                        name=\"routing_weights_round_2\")\n",
        "weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,\n",
        "                                           caps2_predicted,\n",
        "                                           name=\"weighted_predictions_round_2\")\n",
        "weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,\n",
        "                                     axis=1, keep_dims=True,\n",
        "                                     name=\"weighted_sum_round_2\")\n",
        "caps2_output_round_2 = squash(weighted_sum_round_2,\n",
        "                              axis=-2,\n",
        "                              name=\"caps2_output_round_2\")"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "014qYS_E_I_v"
      },
      "source": [
        "caps2_output = caps2_output_round_2"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSxYmJRM_Maq"
      },
      "source": [
        "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
        "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
        "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
        "                                     keep_dims=keep_dims)\n",
        "        return tf.sqrt(squared_norm + epsilon)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IZj69Xe_dsa"
      },
      "source": [
        "y_prob = safe_norm(caps2_output, axis=-2, name=\"y_prob\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPbCFFa8_gv-",
        "outputId": "077461ec-dff8-4ae2-f783-0c45e12dd283"
      },
      "source": [
        "y_prob_argmax = tf.argmax(y_prob, axis=2, name=\"y_prob\")\n",
        "y_prob_argmax"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'y_prob_2:0' shape=(?, 1, 1) dtype=int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbfTjUV1_kxX"
      },
      "source": [
        "y_pred = tf.squeeze(y_prob_argmax, axis=[1,2], name=\"y_pred\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2OpaboP_p2S",
        "outputId": "e12fd28a-61fe-4173-80e9-cdda2b972787"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'y_pred:0' shape=(?,) dtype=int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFPWbUpo_tOY"
      },
      "source": [
        "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TSYqGy__vjV"
      },
      "source": [
        "m_plus = 0.9\n",
        "m_minus = 0.1\n",
        "lambda_ = 0.5"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-Qs80_U_xoy"
      },
      "source": [
        "T = tf.one_hot(y, depth=caps2_amount, name=\"T\")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q7Gpzq4EN7q",
        "outputId": "687cbf43-537c-4581-d2e9-df49e66e77e2"
      },
      "source": [
        "caps2_output"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'caps2_output_round_2/mul:0' shape=(?, 1, 10, 16, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtRUGueV_1GO"
      },
      "source": [
        "caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,\n",
        "                              name=\"caps2_output_norm\")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rj07Iej_6Hr"
      },
      "source": [
        "present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),\n",
        "                              name=\"present_error_raw\")\n",
        "present_error = tf.reshape(present_error_raw, shape=(-1, 10),\n",
        "                           name=\"present_error\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhfrVVA6__KO"
      },
      "source": [
        "absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),\n",
        "                             name=\"absent_error_raw\")\n",
        "absent_error = tf.reshape(absent_error_raw, shape=(-1, 10),\n",
        "                          name=\"absent_error\")"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtIJv9pjAbM-"
      },
      "source": [
        "L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n",
        "           name=\"L\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCIhFfatAhov"
      },
      "source": [
        "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY1IxgKmA22z"
      },
      "source": [
        "mask_with_labels = tf.placeholder_with_default(False, shape=(),\n",
        "                                               name=\"mask_with_labels\")"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh1_QRbyA7xM"
      },
      "source": [
        "reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
        "                                 lambda: y,        # if True\n",
        "                                 lambda: y_pred,   # if False\n",
        "                                 name=\"reconstruction_targets\")"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tm1CP2ZA-Jl",
        "outputId": "34650bd6-5d67-4c12-8fb5-2be0bcdd7c3f"
      },
      "source": [
        "reconstruction_mask = tf.one_hot(reconstruction_targets,\n",
        "                                 depth=caps2_amount,\n",
        "                                 name=\"reconstruction_mask\")\n",
        "reconstruction_mask"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'reconstruction_mask_1:0' shape=(?, 10) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ulIrKcfEr75",
        "outputId": "05fb7bbd-3f8d-47f3-ef03-0a78220d6258"
      },
      "source": [
        "caps2_output"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'caps2_output_round_2/mul:0' shape=(?, 1, 10, 16, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4-bjbIHBJfE"
      },
      "source": [
        "reconstruction_mask_reshaped = tf.reshape(\n",
        "    reconstruction_mask, [-1, 1, caps2_amount, 1, 1],\n",
        "    name=\"reconstruction_mask_reshaped\")"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkXVJfl2BNAN",
        "outputId": "868e0f05-a9a4-4143-c784-259e7a082a11"
      },
      "source": [
        "caps2_output_masked = tf.multiply(\n",
        "    caps2_output, reconstruction_mask_reshaped,\n",
        "    name=\"caps2_output_masked\")\n",
        "caps2_output_masked"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'caps2_output_masked_1:0' shape=(?, 1, 10, 16, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbKxjvqXBTvG",
        "outputId": "ed372791-7f39-4764-8b79-acc5f880073c"
      },
      "source": [
        "decoder_input = tf.reshape(caps2_output_masked,\n",
        "                           [-1, caps2_amount * caps2_dims],\n",
        "                           name=\"decoder_input\")\n",
        "decoder_input"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'decoder_input_1:0' shape=(?, 160) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJcg7lbVBc2C"
      },
      "source": [
        "n_hidden1 = 512\n",
        "n_hidden2 = 1024\n",
        "n_output = 28 * 28"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOWRyP1NBiuY",
        "outputId": "0a32f14b-4878-4c46-ac17-0b917ac6eb3b"
      },
      "source": [
        "with tf.name_scope(\"decoder\"):\n",
        "    hidden1 = tf.layers.dense(decoder_input, n_hidden1,\n",
        "                              activation=tf.nn.relu,\n",
        "                              name=\"hidden1\")\n",
        "    hidden2 = tf.layers.dense(hidden1, n_hidden2,\n",
        "                              activation=tf.nn.relu,\n",
        "                              name=\"hidden2\")\n",
        "    decoder_output = tf.layers.dense(hidden2, n_output,\n",
        "                                     activation=tf.nn.sigmoid,\n",
        "                                     name=\"decoder_output\")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-60-ca7ebd35d3b1>:4: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afrh4EMZBl-F"
      },
      "source": [
        "X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")\n",
        "squared_difference = tf.square(X_flat - decoder_output,\n",
        "                               name=\"squared_difference\")\n",
        "reconstruction_loss = tf.reduce_mean(squared_difference,\n",
        "                                    name=\"reconstruction_loss\")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P-30RjHBxrv"
      },
      "source": [
        "alpha = 0.0005\n",
        "\n",
        "loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ2cIa4NBzwy"
      },
      "source": [
        "correct = tf.equal(y, y_pred, name=\"correct\")\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGp2yW02B4HJ",
        "outputId": "fcc002e9-db06-4e78-e1d6-f0c329c6c7c4"
      },
      "source": [
        "optimizer = tf.train.AdamOptimizer()\n",
        "training_op = optimizer.minimize(loss, name=\"training_op\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhsKvrVtCBk6"
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKexYvOyCDjG"
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 50\n",
        "restore_checkpoint = True\n",
        "\n",
        "n_iterations_per_epoch = mnist.train.num_examples // batch_size\n",
        "n_iterations_validation = mnist.validation.num_examples // batch_size\n",
        "best_loss_val = np.infty\n",
        "checkpoint_path = \"./my_capsule_network\"\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
        "        saver.restore(sess, checkpoint_path)\n",
        "    else:\n",
        "        init.run()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
        "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "            # Run the training operation and measure the loss:\n",
        "            _, loss_train = sess.run(\n",
        "                [training_op, loss],\n",
        "                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
        "                           y: y_batch,\n",
        "                           mask_with_labels: True})\n",
        "            print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
        "                      iteration, n_iterations_per_epoch,\n",
        "                      iteration * 100 / n_iterations_per_epoch,\n",
        "                      loss_train),\n",
        "                  end=\"\")\n",
        "\n",
        "        # At the end of each epoch,\n",
        "        # measure the validation loss and accuracy:\n",
        "        loss_vals = []\n",
        "        acc_vals = []\n",
        "        for iteration in range(1, n_iterations_validation + 1):\n",
        "            X_batch, y_batch = mnist.validation.next_batch(batch_size)\n",
        "            loss_val, acc_val = sess.run(\n",
        "                    [loss, accuracy],\n",
        "                    feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
        "                               y: y_batch})\n",
        "            loss_vals.append(loss_val)\n",
        "            acc_vals.append(acc_val)\n",
        "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
        "                      iteration, n_iterations_validation,\n",
        "                      iteration * 100 / n_iterations_validation),\n",
        "                  end=\" \" * 10)\n",
        "        loss_val = np.mean(loss_vals)\n",
        "        acc_val = np.mean(acc_vals)\n",
        "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
        "            epoch + 1, acc_val * 100, loss_val,\n",
        "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
        "\n",
        "        # And save the model if it improved:\n",
        "        if loss_val < best_loss_val:\n",
        "            save_path = saver.save(sess, checkpoint_path)\n",
        "            best_loss_val = loss_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJXlCi2JCIOu"
      },
      "source": [
        "n_samples = 5\n",
        "\n",
        "sample_images = mnist.test.images[:n_samples].reshape([-1, 28, 28, 1])\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, checkpoint_path)\n",
        "    caps2_output_value, decoder_output_value, y_pred_value = sess.run(\n",
        "            [caps2_output, decoder_output, y_pred],\n",
        "            feed_dict={X: sample_images,\n",
        "                       y: np.array([], dtype=np.int64)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWhGoaPTCWEJ"
      },
      "source": [
        "sample_images = sample_images.reshape(-1, 28, 28)\n",
        "reconstructions = decoder_output_value.reshape([-1, 28, 28])\n",
        "\n",
        "plt.figure(figsize=(n_samples * 2, 3))\n",
        "for index in range(n_samples):\n",
        "    plt.subplot(1, n_samples, index + 1)\n",
        "    plt.imshow(sample_images[index], cmap=\"binary\")\n",
        "    plt.title(\"Label:\" + str(mnist.test.labels[index]))\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(n_samples * 2, 3))\n",
        "for index in range(n_samples):\n",
        "    plt.subplot(1, n_samples, index + 1)\n",
        "    plt.title(\"Predicted:\" + str(y_pred_value[index]))\n",
        "    plt.imshow(reconstructions[index], cmap=\"binary\")\n",
        "    plt.axis(\"off\")\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYWVQ4i-CZGX"
      },
      "source": [
        "def tweak_pose_parameters(output_vectors, min=-0.5, max=0.5, n_steps=11):\n",
        "    steps = np.linspace(min, max, n_steps) # -0.25, -0.15, ..., +0.25\n",
        "    pose_parameters = np.arange(caps2_n_dims) # 0, 1, ..., 15\n",
        "    tweaks = np.zeros([caps2_n_dims, n_steps, 1, 1, 1, caps2_n_dims, 1])\n",
        "    tweaks[pose_parameters, :, 0, 0, 0, pose_parameters, 0] = steps\n",
        "    output_vectors_expanded = output_vectors[np.newaxis, np.newaxis]\n",
        "    return tweaks + output_vectors_expanded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmD1KWs_CbAE"
      },
      "source": [
        "n_steps = 11\n",
        "\n",
        "tweaked_vectors = tweak_pose_parameters(caps2_output_value, n_steps=n_steps)\n",
        "tweaked_vectors_reshaped = tweaked_vectors.reshape(\n",
        "    [-1, 1, caps2_n_caps, caps2_n_dims, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USrCACy8Cc0d"
      },
      "source": [
        "tweak_labels = np.tile(mnist.test.labels[:n_samples], caps2_n_dims * n_steps)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, checkpoint_path)\n",
        "    decoder_output_value = sess.run(\n",
        "            decoder_output,\n",
        "            feed_dict={caps2_output: tweaked_vectors_reshaped,\n",
        "                       mask_with_labels: True,\n",
        "                       y: tweak_labels})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIs9GlN_CelF"
      },
      "source": [
        "tweak_reconstructions = decoder_output_value.reshape(\n",
        "        [caps2_n_dims, n_steps, n_samples, 28, 28])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UOE7M-aCgYm"
      },
      "source": [
        "for dim in range(3):\n",
        "    print(\"Tweaking output dimension #{}\".format(dim))\n",
        "    plt.figure(figsize=(n_steps / 1.2, n_samples / 1.5))\n",
        "    for row in range(n_samples):\n",
        "        for col in range(n_steps):\n",
        "            plt.subplot(n_samples, n_steps, row * n_steps + col + 1)\n",
        "            plt.imshow(tweak_reconstructions[dim, col, row], cmap=\"binary\")\n",
        "            plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}